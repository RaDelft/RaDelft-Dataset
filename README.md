# RaDelft Dataset

This repository shares the documentation for the RaDelf dataset as well as the code for reproducing the results of [1].

<div align="center">
<p float="center">
<img src="docs/figures/exampleVideo.gif" alt="Example video" width="600"/>
<br />
<b>Example video from our dataset, with the camera on top, lidar on the right and the point cloud from [1] on the left.</b>
</p>
</div>

## Overview
- [Introduction](#introduction)
- [Sensors and Data](#sensors-and-data)
- [Annotation](#annotation)
- [Access](#access)
- [Getting Started](#getting-started)
- [Examples and Demo](#examples-and-demos)
- [Citation](#citation)
- [Original paper](NOT YET)
- [Links](#links)


## Changelog

## Introduction

The RaDelft dataset is a large-scale, real-life multi-sensor dataset recorded in various driving scenarios. It provides radar data in different processing levels, synchronised with lidar, camera and odometry.

## Sensors and data
The output of the next sensors have been recorded:

- A texas instruments MIMO radar board MMWCAS-RF-EVM mounted on the roof.
- A RoboSense Ruby Plus Lidar (128 layers rotating lidar) mounted on the roof.
- A video camera mounted on the windshield (1936 x 1216 px, ~30Hz).
- The ego vehicle’s odometry (filtered combination of RTK GPS, IMU, and wheel odometry, ∼100 Hz).

All sensors were jointly calibrated. See the figure below for a general overview of the sensor setup.

<div align="center">
<p float="center">
<img src="docs/figures/car2.png" alt="Example video" width="600"/>
</p>
</div>

## Annotation
Coming soon

## Access
The dataset is made freely available for non-commertial reaseach purposes only. Eligiblity to use the dataset is limited to Master- and PhD- students, and staff of academic and non-profit research institutions.

## Getting Started
Coming soon
## Examples and Demos
Coming soon
## Neural Network
Coming soon
## License
Coming soon
## Citation
Coming soon
## Links
Coming soon
